{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, argparse\n",
    "import cv2\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nishu/kerai/local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "VQA_model_file_name = 'files_all/VQA_MODEL.json'\n",
    "VQA_weights_file_name = 'files_all/VQA_MODEL_WEIGHTS.hdf5'\n",
    "label_encoder_file_name = 'files_all/FULL_labelencoder_trainval.pkl'\n",
    "CNN_weights_file_name = 'models/imageTrain_weights.h5'\n",
    "\n",
    "verbose = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from PyQt4.QtGui import *\n",
    "#from pythonqt4.QtGui import *\n",
    "from PyQt4 import QtCore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_model(CNN_weights_file_name):\n",
    "    from models.CNN_training import image_Train\n",
    "    image_model = image_Train(CNN_weights_file_name)\n",
    "    \n",
    "    sgd = SGD(lr = 0.1,\n",
    "              decay = 1e-6,\n",
    "              momentum = 0.9,\n",
    "              nesterov = True)\n",
    "    \n",
    "    image_model.compile(optimizer = sgd,\n",
    "                       loss = 'categorical_crossentropy')\n",
    "    #print image_model.summary()\n",
    "    return image_model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, os, sys, types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_features(image_file_name, CNN_weights_file_name):\n",
    "    image_features = np.zeros((1,4096))\n",
    "    \n",
    "    im = cv2.resize(cv2.imread(image_file_name), (224, 224))\n",
    "    #im = im.transpose((2,0,1))\n",
    "    \n",
    "    mean_pixel = [103.939, 116.779, 123.68]\n",
    "    \n",
    "    im = im.astype(np.float32, copy=False)\n",
    "    \n",
    "    for c in range(3):\n",
    "        im[:, :, c] = im[: ,: ,c] - mean_pixel[c]\n",
    "        \n",
    "    im = im.transpose((2,0,1))\n",
    "    \n",
    "    im = np.expand_dims(im, axis=0)\n",
    "    \n",
    "    image_features[0,:] = get_image_model(CNN_weights_file_name).predict(im)[0]\n",
    "    \n",
    "    return image_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_question_features(question):\n",
    "    word_embeddings = spacy.load('en', vectors= 'en_glove_cc_300_1m_vectors')\n",
    "    tokens = word_embeddings(question)\n",
    "    question_tensor = np.zeros((1, 30, 300))\n",
    "    \n",
    "    for j in xrange(len(tokens)):\n",
    "        question_tensor[0, j, :] = tokens[j].vector[:300]\n",
    "        \n",
    "    return question_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_VQA_model(VQA_model_file_name):\n",
    "    from files_all.VQA import VQA_MODEL\n",
    "    vqa_model = VQA_MODEL()\n",
    "    #vqa_model = model_from_json(open(VQA_model_file_name).read())\n",
    "    vqa_model.load_weights(VQA_weights_file_name)\n",
    "    vqa_model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "    \n",
    "    #print vqa_model.summary()\n",
    "    \n",
    "    return vqa_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyQt4 import QtGui\n",
    "class VQA_demo(QtGui.QWidget):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(VQA_demo, self).__init__()     \n",
    "        self.initUI()\n",
    "            \n",
    "    def initUI(self): \n",
    "\n",
    "        self.image_file_name = None\n",
    "        self.question = None              \n",
    "        \n",
    "        self.l1=QtGui.QLabel()\n",
    "        self.lbl_qstn=QtGui.QLabel()\n",
    "        self.lbl_output=QtGui.QLabel()\n",
    "        self.lbl_output.setAlignment(QtCore.Qt.AlignCenter)\n",
    "        \n",
    "        self.input_qstn = QtGui.QLineEdit()\n",
    "         # Text edit\n",
    "        \n",
    "        self.progress = QtGui.QProgressBar(self)\n",
    "        self.progress.setAlignment(QtCore.Qt.AlignCenter)\n",
    "        \n",
    "        font=QtGui.QFont()\n",
    "        font.setPointSize(20)\n",
    "        font.setBold(True)\n",
    "        self.l1.setFont(font)\n",
    "        self.l1.setText(\"<font color='black'> Choose the image file </font>\")\n",
    "        self.lbl_qstn.setFont(font)\n",
    "        self.lbl_qstn.setText(\"<font color='black'> Question </font>\")\n",
    "        self.lbl_output.setFont(font)\n",
    "        self.lbl_output.setText(\"<font color='black'> Answer </font>\")\n",
    "        \n",
    "        self.te = QtGui.QTextEdit()\n",
    "        font1 = QtGui.QFont()\n",
    "        font1.setFamily('Lucida')\n",
    "        font1.setFixedPitch(True)\n",
    "        font1.setPointSize(20)\n",
    "        font1.setBold(True)\n",
    "        self.te.setFont(font1)\n",
    "        self.input_qstn.setFont(font1)\n",
    "        \n",
    "        self.img_input=QtGui.QLabel()\n",
    "        self.img_input.resize(self.img_input.sizeHint())  \n",
    "        self.img_input.setAlignment(QtCore.Qt.AlignCenter)\n",
    "        \n",
    "        self.img_output=QtGui.QLabel()\n",
    "        self.img_output.setAlignment(QtCore.Qt.AlignCenter)\n",
    "        self.img_output.resize(self.img_output.sizeHint())        \n",
    "        \n",
    "        \n",
    "        self.btn_browse=QtGui.QPushButton(\"Browse\")        \n",
    "        self.btn_browse.clicked.connect(self.Browse)\n",
    "        self.btn_browse.resize(self.btn_browse.sizeHint())\n",
    "\n",
    "        self.btn_start=QtGui.QPushButton(\"PREDICT\")        \n",
    "        self.btn_start.clicked.connect(self.start_prediction)\n",
    "        self.btn_start.resize(self.btn_start.sizeHint())  \n",
    "        \n",
    "        self.btn_close=QtGui.QPushButton(\"QUIT\")        \n",
    "#        self.btn_close.clicked.connect(self.close_event)\n",
    "        self.btn_close.clicked.connect(self.close)\n",
    "        self.btn_close.resize(self.btn_close.sizeHint())\n",
    "        \n",
    "        layout1 = QtGui.QHBoxLayout()\n",
    "        layout1.addWidget(self.l1)\n",
    "        layout1.addWidget(self.btn_browse)\n",
    "        \n",
    "        layout2 = QtGui.QHBoxLayout()\n",
    "        layout2.addWidget(self.lbl_qstn)\n",
    "        layout2.addWidget(self.input_qstn)\n",
    "          \n",
    "        vbox_inpt=QtGui.QVBoxLayout()\n",
    "        vbox_inpt.setMargin(0)\n",
    "        vbox_inpt.addLayout(layout1)\n",
    "        vbox_inpt.addLayout(layout2)\n",
    "#        vbox_inpt.addWidget(self.btn_browse)\n",
    "        vbox_inpt.addWidget(self.img_input)\n",
    "        \n",
    "        vbox_opt=QtGui.QVBoxLayout()\n",
    "        vbox_opt.setMargin(0)\n",
    "        vbox_opt.addWidget(self.lbl_output)\n",
    "        vbox_opt.addWidget(self.progress)\n",
    "        vbox_opt.addWidget(self.te)\n",
    "        \n",
    "#        hbox2.addStretch(0)   \n",
    "        \n",
    "        hbox=QtGui.QHBoxLayout()\n",
    "        hbox.addLayout(vbox_inpt)\n",
    "        hbox.addLayout(vbox_opt)\n",
    "        \n",
    "        vbox_main=QtGui.QVBoxLayout()\n",
    "        vbox_main.addLayout(hbox)\n",
    "#        vbox_main.addWidget(self.te)\n",
    "        vbox_main.addWidget(self.btn_start)\n",
    "        vbox_main.addWidget(self.btn_close)\n",
    "#        fbox.addRow(hbox1)\n",
    "        \n",
    "        self.setLayout(vbox_main)\n",
    "        self.setGeometry(200, 200, 1200, 700)\n",
    "        self.setWindowTitle(\"VQA-DEMO-demo\")\n",
    "        self.setWindowIcon(QtGui.QIcon('vqa_logo.png'))\n",
    "\n",
    "        self.fname=None\n",
    "        self.result=None\n",
    "        \n",
    "#        self.progress.setGeometry(200, 80, 250, 20)\n",
    "        self.show()     \n",
    "       \n",
    "    def Browse(self):\n",
    "\n",
    "        w = QtGui.QWidget()            \n",
    "        QtGui.QMessageBox.information(w,\"Message\", \"Please select an image file\")          \n",
    "        \n",
    "        filePath = QtGui.QFileDialog.getOpenFileName(self, '*.')\n",
    "        print('filePath',filePath, '\\n')\n",
    "        self.fname=str(filePath)\n",
    "        self.img_input.setPixmap(QtGui.QPixmap(filePath))\n",
    "        self.img_input.setScaledContents(True)\n",
    "        self.image_file_name=self.fname\n",
    "        \n",
    "    \n",
    "    \n",
    "    def start_prediction(self):\n",
    "        #        cmd = str(self.le.text()\n",
    "        #        stdouterr = os.popen4(cmd)[1].read()\n",
    "        #        self.te.setText('lets\\n\\n'+'start')\n",
    "        \n",
    "        \n",
    "        self.completed = 0\n",
    "        self.te.setText('')\n",
    "        \n",
    "        \n",
    "        #        self.completed = 15\n",
    "        self.progress.setValue(15)\n",
    "        if verbose : print(\"\\n\\n\\nLoading image features ...\")\n",
    "\n",
    "        image_features = get_image_features(self.image_file_name, CNN_weights_file_name)\n",
    "        \n",
    "        \n",
    "        self.progress.setValue(40)\n",
    "        if verbose : print(\"Loading question features ...\")\n",
    "\n",
    "        \n",
    "        self.question = self.input_qstn.text()\n",
    "\n",
    "        question_features = get_question_features(unicode(self.question,'utf-8'))\n",
    "    \n",
    "       \n",
    "        self.progress.setValue(70)\n",
    "        if verbose : print(\"Loading VQA Model ...\")\n",
    "            \n",
    "        vqa_model = get_VQA_model(VQA_weights_file_name)\n",
    "    \n",
    "        self.progress.setValue(100)\n",
    "        if verbose : print(\"\\n\\n\\nPredicting result ...\")\n",
    "        \n",
    "        y_output = vqa_model.predict([question_features, image_features])\n",
    "        y_sort_index = np.argsort(y_output)\n",
    "    \n",
    "        # This task here is represented as a classification into a 1000 top answers\n",
    "        # this means some of the answers were not part of trainng and thus would \n",
    "        # not show up in the result.\n",
    "        # These 1000 answers are stored in the sklearn Encoder class\n",
    "        labelencoder = joblib.load(label_encoder_file_name)\n",
    "        self.result=[]\n",
    "        for label in reversed(y_sort_index[0,-5:]):\n",
    "            print str(round(y_output[0,label]*100,2)).zfill(5)+ \" % \"+ labelencoder.inverse_transform(label)\n",
    "            cmd=str(round(y_output[0,label]*100,2)).zfill(5)+ \" % \"+ labelencoder.inverse_transform(label)\n",
    "            #            stdouterr = os.popen4(cmd)[1].read()\n",
    "            self.result.append(cmd)\n",
    "        self.te.setText('Top 5 predictions : ' + '\\n' +  '\\n'+self.result[0] + '\\n' + self.result[1]\n",
    "        + '\\n' + self.result[2]+ '\\n' + self.result[3]+ '\\n' + self.result[4])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('filePath', PyQt4.QtCore.QString(u'/home/nishu/Desktop/project/VQA_trials_and_tribulations/indparksoccerkids.jpg'), '\\n')\n",
      "\n",
      "\n",
      "\n",
      "Loading image features ...\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \n",
    "    \n",
    "    app = QtGui.QApplication(sys.argv)\n",
    "    ex = VQA_demo()\n",
    "    app.exec_()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
